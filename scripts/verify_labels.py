"""
Script para verificar e explorar as labels do dataset fonte.
√ötil para confirmar que estamos usando a coluna correta.
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

import pandas as pd
from loguru import logger

from src.data_loading.source_loaders import ElectricalFaultLoader


def verify_labels():
    """
    Verifica as colunas de labels dispon√≠veis no dataset e suas distribui√ß√µes.
    """
    logger.info("=" * 80)
    logger.info("VERIFICA√á√ÉO DE LABELS DO DATASET FONTE")
    logger.info("=" * 80)
    
    # Carregar dataset
    loader = ElectricalFaultLoader()
    
    try:
        df = loader.load()
    except FileNotFoundError as e:
        logger.error(str(e))
        return
    
    # Listar todas as colunas
    logger.info(f"\nüìã Todas as colunas do dataset:")
    for i, col in enumerate(df.columns, 1):
        logger.info(f"  {i}. {col} ({df[col].dtype})")
    
    # Analisar colunas categ√≥ricas relevantes para labels
    categorical_cols = df.select_dtypes(include=['object']).columns
    
    logger.info(f"\nüè∑Ô∏è  Colunas categ√≥ricas (poss√≠veis labels):")
    for col in categorical_cols:
        if any(keyword in col.lower() for keyword in ['fault', 'health', 'status', 'type']):
            logger.info(f"\n  üìå {col}:")
            value_counts = df[col].value_counts()
            for value, count in value_counts.items():
                percentage = (count / len(df)) * 100
                logger.info(f"      - {value}: {count} ({percentage:.1f}%)")
    
    # An√°lise espec√≠fica de Component Health
    if 'Component Health' in df.columns:
        logger.info("\n" + "=" * 80)
        logger.info("AN√ÅLISE DETALHADA: Component Health")
        logger.info("=" * 80)
        
        health_col = df['Component Health']
        
        logger.info(f"\nüìä Distribui√ß√£o completa:")
        for value, count in health_col.value_counts().items():
            percentage = (count / len(df)) * 100
            logger.info(f"  {value:15s}: {count:4d} ({percentage:5.1f}%)")
        
        # Criar labels bin√°rias
        logger.info(f"\nüîÑ Convers√£o para labels bin√°rias:")
        logger.info(f"  Normal       ‚Üí 0 (N√£o anomalia)")
        logger.info(f"  Faulty       ‚Üí 1 (Anomalia)")
        logger.info(f"  Overheated   ‚Üí 1 (Anomalia)")
        
        binary_labels = (health_col != 'Normal').astype(int)
        
        logger.info(f"\n‚úÖ Resultado:")
        logger.info(f"  Classe 0 (Normal):   {sum(binary_labels == 0):4d} ({sum(binary_labels == 0)/len(df)*100:.1f}%)")
        logger.info(f"  Classe 1 (Anomalia): {sum(binary_labels == 1):4d} ({sum(binary_labels == 1)/len(df)*100:.1f}%)")
        
        # Verificar balanceamento
        imbalance_ratio = max(sum(binary_labels == 0), sum(binary_labels == 1)) / min(sum(binary_labels == 0), sum(binary_labels == 1))
        logger.info(f"\n‚öñÔ∏è  Raz√£o de desbalanceamento: {imbalance_ratio:.2f}:1")
        
        if imbalance_ratio > 3:
            logger.warning("  ‚ö†Ô∏è  Dataset desbalanceado! Considere usar:")
            logger.warning("     - Class weights no modelo")
            logger.warning("     - SMOTE para oversampling")
            logger.warning("     - Ajustar contamination adequadamente")
        else:
            logger.info("  ‚úì Dataset razoavelmente balanceado")
    
    # An√°lise de correla√ß√£o entre Fault Type e Component Health (se ambas existirem)
    if 'Component Health' in df.columns and 'Fault Type' in df.columns:
        logger.info("\n" + "=" * 80)
        logger.info("CORRELA√á√ÉO: Component Health vs Fault Type")
        logger.info("=" * 80)
        
        cross_tab = pd.crosstab(df['Component Health'], df['Fault Type'], margins=True)
        logger.info("\nüìä Tabela cruzada:")
        logger.info(f"\n{cross_tab}")
        
        logger.info("\nüí° Interpreta√ß√£o:")
        logger.info("  Esta tabela mostra como Component Health se relaciona com Fault Type")
        logger.info("  √ötil para entender se as duas colunas capturam informa√ß√µes diferentes")
    
    # Testar carregamento com a nova implementa√ß√£o
    logger.info("\n" + "=" * 80)
    logger.info("TESTE: Carregamento com load_preprocessed()")
    logger.info("=" * 80)
    
    try:
        X, y = loader.load_preprocessed(label_column='Component Health')
        logger.info(f"\n‚úÖ Sucesso!")
        logger.info(f"  Features: {X.shape}")
        logger.info(f"  Labels: {y.shape}")
        logger.info(f"  Distribui√ß√£o: Normal={sum(y==0)}, Anomalia={sum(y==1)}")
        
        # Mostrar algumas amostras
        logger.info(f"\nüìù Primeiras 5 amostras:")
        sample_df = pd.concat([X.head(), y.head().rename('Label')], axis=1)
        logger.info(f"\n{sample_df}")
        
    except Exception as e:
        logger.error(f"\n‚ùå Erro ao carregar: {e}")
    
    logger.info("\n" + "=" * 80)
    logger.info("VERIFICA√á√ÉO CONCLU√çDA")
    logger.info("=" * 80)
    
    # Recomenda√ß√µes
    logger.info("\nüí° RECOMENDA√á√ïES:")
    logger.info("  1. Use label_column='Component Health' para treinamento")
    logger.info("  2. Normal = n√£o anomalia (0)")
    logger.info("  3. Faulty + Overheated = anomalia (1)")
    logger.info("  4. Ajuste contamination baseado na propor√ß√£o real de anomalias")
    
    if 'Component Health' in df.columns:
        anomaly_rate = sum(binary_labels == 1) / len(df)
        logger.info(f"  5. Contamination sugerido: {anomaly_rate:.2f}")


if __name__ == "__main__":
    verify_labels()